{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks\n",
    "- https://skymind.ai/wiki/generative-adversarial-network-gan\n",
    "- https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29\n",
    "- https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf\n",
    "- https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/\n",
    "- https://arxiv.org/pdf/1511.06434.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'imresize' from 'scipy.misc' (C:\\Users\\darrahts\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\scipy\\misc\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-706776c5c832>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimresize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'imresize' from 'scipy.misc' (C:\\Users\\darrahts\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\scipy\\misc\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import zipfile\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, alpha=.2):\n",
    "    return tf.maximum(alpha*x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(object):\n",
    "    def __init__(self, name, sz_in, sz_out, apply_batch_norm=True, sz_filter=5, stride=2, activation=tf.nn.relu):\n",
    "        \"\"\"\n",
    "            Descr: initializes a convolution layer\n",
    "            \n",
    "            Params:\n",
    "                name:\n",
    "                sz_in:\n",
    "                sz_out:\n",
    "                apply_batch_norm:\n",
    "                sz_filter:\n",
    "                stride:\n",
    "                activation:\n",
    "        \"\"\"\n",
    "        self.W = tf.get_variable(\"W_%s\" % name, shape=(sz_filter, sz_filter, sz_in, sz_out), initializer=tf.truncated_normal_initializer(stddev=.02))\n",
    "        self.b = tf.get_variable(\"b_%s\" % name, shape=(sz_out,), initializer=tf.zeros_initializer())\n",
    "        \n",
    "        self.name = name\n",
    "        self.activation = activation\n",
    "        self.stride = stride\n",
    "        self.apply_batch_norm = apply_batch_norm\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "    def forward(self, X, reuse, is_training, decay=.9, epsilon=1e-5):\n",
    "        \"\"\"\n",
    "            Descr: performs feedforward operation on a layer\n",
    "            \n",
    "            Params:\n",
    "                X:\n",
    "                reuse:\n",
    "                is_training:\n",
    "                decay:\n",
    "                epsilon:\n",
    "        \"\"\"\n",
    "        conv_out = tf.nn.conv2d(X, self.W, strides=[1, self.stride, self.stride, 1], padding='SAME')\n",
    "        conv_out = tf.nn.bias_add(conv_out, self.b)\n",
    "        \n",
    "        if(self.apply_batch_norm):\n",
    "            conv_out = tf.contrib.layers.batch_norm(conv_out, decay=decay, updates_collections=None, epsilon=epsilon, scale=True, is_training=is_training, reuse=reuse, scope=self.name)\n",
    "        \n",
    "        return self.activation(conv_out)\n",
    "    \n",
    "class FractionStrideConvLayer(object):\n",
    "    def __init__(self, name, sz_in, sz_out, output_shape, apply_batch_norm=True, sz_filter=5, stride=2, activation=tf.nn.relu):\n",
    "        \"\"\"\n",
    "            Descr: initializes a fractionally strided convolution layer (i.e. deconvolution)\n",
    "            \n",
    "            Params:\n",
    "                name:\n",
    "                sz_in:\n",
    "                sz_out:\n",
    "                output_shape:\n",
    "                apply_batch_norm:\n",
    "                sz_filter:\n",
    "                stride:\n",
    "                activation:\n",
    "        \"\"\"\n",
    "        self.W = tf.get_variable(\"W_%s\" % name, shape=(sz_filter, sz_filter, sz_out, sz_in), initializer=tf.random_normal_initializer(stddev=.02))\n",
    "        self.b = tf.get_variable(\"b_%s\" % name, shape=(sz_out,), initializer=tf.zeros_initializer())\n",
    "        \n",
    "        self.name = name\n",
    "        self.activation = activation\n",
    "        self.stride = stride\n",
    "        self.apply_batch_norm = apply_batch_norm\n",
    "        self.output_shape = output_shape\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "    def forward(self, X, reuse, is_training, decay=.9, epsilon=1e-5):\n",
    "        \"\"\"\n",
    "            Descr: performs feedforward operation on a layer\n",
    "            \n",
    "            Params:\n",
    "                X:\n",
    "                reuse:\n",
    "                is_training:\n",
    "                decay:\n",
    "                epsilon:\n",
    "        \"\"\"\n",
    "        conv_out = tf.nn.conv2d_transpose(value=X, filter=self.W, output_shape=self.output_shape, strides=[1, self.stride, self.stride, 1])\n",
    "        conv_out = tf.nn.bias_add(conv_out, self.b)\n",
    "        \n",
    "        if(self.apply_batch_norm):\n",
    "            conv_out = tf.contrib.layers.batch_norm(conv_out, decay=decay, updates_collections=None, epsilon=epsilon, scale=True, is_training=is_training, reuse=reuse, scope=self.name)\n",
    "        \n",
    "        return self.activation(conv_out)\n",
    "        \n",
    "class DenseLayer(object):\n",
    "    def __init__(self, name, sz_in, sz_out, apply_batch_norm=True, activation=tf.nn.relu):\n",
    "        \"\"\"\n",
    "            Descr: initializes a fully connected layer\n",
    "            \n",
    "            Params:\n",
    "                name:\n",
    "                sz_in:\n",
    "                sz_out:\n",
    "                apply_batch_norm:\n",
    "                activation:\n",
    "        \"\"\"\n",
    "        self.W = tf.get_variable(\"W_%s\" % name, shape=(sz_in, sz_out), initializer=tf.random_normal_initializer(stddev=.02))\n",
    "        self.b = tf.get_variable(\"b_%s\" % name, shape=(sz_out, ), initializer=tf.zeros_initializer())\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.name = name\n",
    "        self.apply_batch_norm = apply_batch_norm\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "    def forward(self, X, reuse, is_training, decay=.9, epsilon=1e-5):\n",
    "        \"\"\"\n",
    "            Descr: performs feedforward operation on a layer\n",
    "            \n",
    "            Params:\n",
    "                X:\n",
    "                reuse:\n",
    "                is_training:\n",
    "                decay:\n",
    "                epsilon:\n",
    "        \"\"\"\n",
    "        layer_out = tf.matmul(X, self.W) + self.b\n",
    "        \n",
    "        if(self.apply_batch_norm):\n",
    "            layer_out = tf.contrib.layers.batch_norm(layer_out, decay=decay, updates_collections=None, epsilon=epsilon, scale=True, is_training=is_training, reuse=reuse, scope=self.name)\n",
    "        \n",
    "        return self.activation(layer_out)     \n",
    "    \n",
    "class DCGAN(object):\n",
    "    def __init__(self, img_length, num_colors, d_sizes, g_sizes):\n",
    "        \"\"\"\n",
    "            Descr: initializes a DCGAN network\n",
    "            \n",
    "            Params:\n",
    "                img_length:\n",
    "                num_colors:\n",
    "                d_sizes:\n",
    "                g_sizes:\n",
    "        \"\"\"\n",
    "        # save for later\n",
    "        self.img_length = img_length\n",
    "        self.num_colors = num_colors\n",
    "        self.latent_dims = g_sizes['z']\n",
    "\n",
    "        # define the input data\n",
    "        self.X = tf.placeholder(\n",
    "          tf.float32,\n",
    "          shape=(None, img_length, img_length, num_colors),\n",
    "          name='X'\n",
    "        )\n",
    "        self.Z = tf.placeholder(\n",
    "          tf.float32,\n",
    "          shape=(None, self.latent_dims),\n",
    "          name='Z'\n",
    "        )\n",
    "\n",
    "        # note: by making batch_sz a placeholder, we can specify a variable\n",
    "        # number of samples in the FS-conv operation where we are required\n",
    "        # to pass in output_shape\n",
    "        # we need only pass in the batch size via feed_dict\n",
    "        self.batch_sz = tf.placeholder(tf.int32, shape=(), name='batch_sz')\n",
    "\n",
    "        # build the discriminator\n",
    "        logits = self.build_discriminator(self.X, d_sizes)\n",
    "\n",
    "        # build generator\n",
    "        self.sample_images = self.build_generator(self.Z, g_sizes)\n",
    "\n",
    "        # get sample logits\n",
    "        with tf.variable_scope(\"discriminator\") as scope:\n",
    "            scope.reuse_variables()\n",
    "            sample_logits = self.d_forward(self.sample_images, True)\n",
    "\n",
    "        # get sample images for test time (batch norm is different)\n",
    "        with tf.variable_scope(\"generator\") as scope:\n",
    "            scope.reuse_variables()\n",
    "            self.sample_images_test = self.g_forward(\n",
    "            self.Z, reuse=True, is_training=False\n",
    "            )\n",
    "\n",
    "        # build costs\n",
    "        self.d_cost_real = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "          logits=logits,\n",
    "          labels=tf.ones_like(logits)\n",
    "        )\n",
    "        self.d_cost_fake = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "          logits=sample_logits,\n",
    "          labels=tf.zeros_like(sample_logits)\n",
    "        )\n",
    "        self.d_cost = tf.reduce_mean(self.d_cost_real) + tf.reduce_mean(self.d_cost_fake)\n",
    "        self.g_cost = tf.reduce_mean(\n",
    "          tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=sample_logits,\n",
    "            labels=tf.ones_like(sample_logits)\n",
    "          )\n",
    "        )\n",
    "        real_predictions = tf.cast(logits > 0, tf.float32)\n",
    "        fake_predictions = tf.cast(sample_logits < 0, tf.float32)\n",
    "        num_predictions = 2.0*BATCH_SIZE\n",
    "        num_correct = tf.reduce_sum(real_predictions) + tf.reduce_sum(fake_predictions)\n",
    "        self.d_accuracy = num_correct / num_predictions\n",
    "\n",
    "\n",
    "        # optimizers\n",
    "        self.d_params = [t for t in tf.trainable_variables() if t.name.startswith('d')]\n",
    "        self.g_params = [t for t in tf.trainable_variables() if t.name.startswith('g')]\n",
    "\n",
    "        self.d_train_op = tf.train.AdamOptimizer(\n",
    "          LEARNING_RATE, beta1=BETA1\n",
    "        ).minimize(\n",
    "          self.d_cost, var_list=self.d_params\n",
    "        )\n",
    "        self.g_train_op = tf.train.AdamOptimizer(\n",
    "          LEARNING_RATE, beta1=BETA1\n",
    "        ).minimize(\n",
    "          self.g_cost, var_list=self.g_params\n",
    "        )\n",
    "\n",
    "        # show_all_variables()\n",
    "        # exit()\n",
    "\n",
    "        # set up session and variables for later\n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(self.init_op)\n",
    "\n",
    "\n",
    "    def build_discriminator(self, X, d_sizes):\n",
    "        with tf.variable_scope(\"discriminator\") as scope:\n",
    "\n",
    "            # build conv layers\n",
    "            self.d_convlayers = []\n",
    "            mi = self.num_colors\n",
    "            dim = self.img_length\n",
    "            count = 0\n",
    "            for mo, filtersz, stride, apply_batch_norm in d_sizes['conv_layers']:\n",
    "                # make up a name - used for get_variable\n",
    "                name = \"convlayer_%s\" % count\n",
    "                count += 1\n",
    "\n",
    "                layer = ConvLayer(name, mi, mo, apply_batch_norm, filtersz, stride, lrelu)\n",
    "                self.d_convlayers.append(layer)\n",
    "                mi = mo\n",
    "                print(\"dim:\", dim)\n",
    "                dim = int(np.ceil(float(dim) / stride))\n",
    "\n",
    "\n",
    "            mi = mi * dim * dim\n",
    "            # build dense layers\n",
    "            self.d_denselayers = []\n",
    "            for mo, apply_batch_norm in d_sizes['dense_layers']:\n",
    "                name = \"denselayer_%s\" % count\n",
    "                count += 1\n",
    "\n",
    "                layer = DenseLayer(name, mi, mo, apply_batch_norm, lrelu)\n",
    "                mi = mo\n",
    "                self.d_denselayers.append(layer)\n",
    "\n",
    "\n",
    "            # final logistic layer\n",
    "            name = \"denselayer_%s\" % count\n",
    "            self.d_finallayer = DenseLayer(name, mi, 1, False, lambda x: x)\n",
    "\n",
    "            # get the logits\n",
    "            logits = self.d_forward(X)\n",
    "\n",
    "            # build the cost later\n",
    "            return logits\n",
    "\n",
    "\n",
    "    def d_forward(self, X, reuse=None, is_training=True):\n",
    "        # encapsulate this because we use it twice\n",
    "        output = X\n",
    "        for layer in self.d_convlayers:\n",
    "            output = layer.forward(output, reuse, is_training)\n",
    "        output = tf.contrib.layers.flatten(output)\n",
    "        for layer in self.d_denselayers:\n",
    "            output = layer.forward(output, reuse, is_training)\n",
    "        logits = self.d_finallayer.forward(output, reuse, is_training)\n",
    "        return logits\n",
    "\n",
    "\n",
    "    def build_generator(self, Z, g_sizes):\n",
    "        with tf.variable_scope(\"generator\") as scope:\n",
    "\n",
    "            # determine the size of the data at each step\n",
    "            dims = [self.img_length]\n",
    "            dim = self.img_length\n",
    "            for _, _, stride, _ in reversed(g_sizes['conv_layers']):\n",
    "                dim = int(np.ceil(float(dim) / stride))\n",
    "                dims.append(dim)\n",
    "\n",
    "            # note: dims is actually backwards\n",
    "            # the first layer of the generator is actually last\n",
    "            # so let's reverse it\n",
    "            dims = list(reversed(dims))\n",
    "            print(\"dims:\", dims)\n",
    "            self.g_dims = dims\n",
    "\n",
    "\n",
    "            # dense layers\n",
    "            mi = self.latent_dims\n",
    "            self.g_denselayers = []\n",
    "            count = 0\n",
    "            for mo, apply_batch_norm in g_sizes['dense_layers']:\n",
    "                name = \"g_denselayer_%s\" % count\n",
    "                count += 1\n",
    "\n",
    "                layer = DenseLayer(name, mi, mo, apply_batch_norm)\n",
    "                self.g_denselayers.append(layer)\n",
    "                mi = mo\n",
    "\n",
    "            # final dense layer\n",
    "            mo = g_sizes['projection'] * dims[0] * dims[0]\n",
    "            name = \"g_denselayer_%s\" % count\n",
    "            layer = DenseLayer(name, mi, mo, not g_sizes['bn_after_project'])\n",
    "            self.g_denselayers.append(layer)\n",
    "\n",
    "\n",
    "            # fs-conv layers\n",
    "            mi = g_sizes['projection']\n",
    "            self.g_convlayers = []\n",
    "\n",
    "            # output may use tanh or sigmoid\n",
    "            num_relus = len(g_sizes['conv_layers']) - 1\n",
    "            activation_functions = [tf.nn.relu]*num_relus + [g_sizes['output_activation']]\n",
    "\n",
    "            for i in range(len(g_sizes['conv_layers'])):\n",
    "                name = \"fs_convlayer_%s\" % i\n",
    "                mo, filtersz, stride, apply_batch_norm = g_sizes['conv_layers'][i]\n",
    "                f = activation_functions[i]\n",
    "                output_shape = [self.batch_sz, dims[i+1], dims[i+1], mo]\n",
    "                print(\"mi:\", mi, \"mo:\", mo, \"outp shape:\", output_shape)\n",
    "                layer = FractionallyStridedConvLayer(\n",
    "                  name, mi, mo, output_shape, apply_batch_norm, filtersz, stride, f\n",
    "                )\n",
    "                self.g_convlayers.append(layer)\n",
    "                mi = mo\n",
    "\n",
    "            # get the output\n",
    "            self.g_sizes = g_sizes\n",
    "            return self.g_forward(Z)\n",
    "\n",
    "\n",
    "    def g_forward(self, Z, reuse=None, is_training=True):\n",
    "        # dense layers\n",
    "        output = Z\n",
    "        for layer in self.g_denselayers:\n",
    "            output = layer.forward(output, reuse, is_training)\n",
    "\n",
    "        # project and reshape\n",
    "        output = tf.reshape(\n",
    "        output,\n",
    "        [-1, self.g_dims[0], self.g_dims[0], self.g_sizes['projection']],\n",
    "        )\n",
    "\n",
    "        # apply batch norm\n",
    "        if self.g_sizes['bn_after_project']:\n",
    "            output = tf.contrib.layers.batch_norm(\n",
    "            output,\n",
    "            decay=0.9, \n",
    "            updates_collections=None,\n",
    "            epsilon=1e-5,\n",
    "            scale=True,\n",
    "            is_training=is_training,\n",
    "            reuse=reuse,\n",
    "            scope='bn_after_project'\n",
    "            )\n",
    "\n",
    "        # pass through fs-conv layers\n",
    "        for layer in self.g_convlayers:\n",
    "            output = layer.forward(output, reuse, is_training)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "    def fit(self, X):\n",
    "        d_costs = []\n",
    "        g_costs = []\n",
    "\n",
    "        N = len(X)\n",
    "        n_batches = N // BATCH_SIZE\n",
    "        total_iters = 0\n",
    "        for i in range(EPOCHS):\n",
    "            print(\"epoch:\", i)\n",
    "            np.random.shuffle(X)\n",
    "            for j in range(n_batches):\n",
    "                t0 = datetime.now()\n",
    "\n",
    "                if type(X[0]) is str:\n",
    "                    # is celeb dataset\n",
    "                    batch = util.files2images(\n",
    "                    X[j*BATCH_SIZE:(j+1)*BATCH_SIZE]\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    # is mnist dataset\n",
    "                    batch = X[j*BATCH_SIZE:(j+1)*BATCH_SIZE]\n",
    "\n",
    "                Z = np.random.uniform(-1, 1, size=(BATCH_SIZE, self.latent_dims))\n",
    "\n",
    "                # train the discriminator\n",
    "                _, d_cost, d_acc = self.sess.run(\n",
    "                (self.d_train_op, self.d_cost, self.d_accuracy),\n",
    "                feed_dict={self.X: batch, self.Z: Z, self.batch_sz: BATCH_SIZE},\n",
    "                )\n",
    "                d_costs.append(d_cost)\n",
    "\n",
    "                # train the generator\n",
    "                _, g_cost1 = self.sess.run(\n",
    "                (self.g_train_op, self.g_cost),\n",
    "                feed_dict={self.Z: Z, self.batch_sz: BATCH_SIZE},\n",
    "                )\n",
    "                # g_costs.append(g_cost1)\n",
    "                _, g_cost2 = self.sess.run(\n",
    "                (self.g_train_op, self.g_cost),\n",
    "                feed_dict={self.Z: Z, self.batch_sz: BATCH_SIZE},\n",
    "                )\n",
    "                g_costs.append((g_cost1 + g_cost2)/2) # just use the avg\n",
    "\n",
    "                print(\"  batch: %d/%d  -  dt: %s - d_acc: %.2f\" % (j+1, n_batches, datetime.now() - t0, d_acc))\n",
    "\n",
    "\n",
    "                # save samples periodically\n",
    "                total_iters += 1\n",
    "                if total_iters % SAVE_SAMPLE_PERIOD == 0:\n",
    "                    print(\"saving a sample...\")\n",
    "                    samples = self.sample(64) # shape is (64, D, D, color)\n",
    "\n",
    "                    # for convenience\n",
    "                    d = self.img_length\n",
    "\n",
    "                    if samples.shape[-1] == 1:\n",
    "                        # if color == 1, we want a 2-D image (N x N)\n",
    "                        samples = samples.reshape(64, d, d)\n",
    "                        flat_image = np.empty((8*d, 8*d))\n",
    "\n",
    "                        k = 0\n",
    "                        for i in range(8):\n",
    "                            for j in range(8):\n",
    "                                flat_image[i*d:(i+1)*d, j*d:(j+1)*d] = samples[k].reshape(d, d)\n",
    "                                k += 1\n",
    "\n",
    "                        # plt.imshow(flat_image, cmap='gray')\n",
    "                    else:\n",
    "                        # if color == 3, we want a 3-D image (N x N x 3)\n",
    "                        flat_image = np.empty((8*d, 8*d, 3))\n",
    "                        k = 0\n",
    "                        for i in range(8):\n",
    "                            for j in range(8):\n",
    "                                flat_image[i*d:(i+1)*d, j*d:(j+1)*d] = samples[k]\n",
    "                                k += 1\n",
    "                        # plt.imshow(flat_image)\n",
    "\n",
    "                    # plt.savefig('samples/samples_at_iter_%d.png' % total_iters)\n",
    "                    sp.misc.imsave(\n",
    "                    'samples/samples_at_iter_%d.png' % total_iters,\n",
    "                    flat_image,\n",
    "                    )\n",
    "\n",
    "        # save a plot of the costs\n",
    "        plt.clf()\n",
    "        plt.plot(d_costs, label='discriminator cost')\n",
    "        plt.plot(g_costs, label='generator cost')\n",
    "        plt.legend()\n",
    "        plt.savefig('cost_vs_iteration.png')\n",
    "\n",
    "    def sample(self, n):\n",
    "        Z = np.random.uniform(-1, 1, size=(n, self.latent_dims))\n",
    "        samples = self.sess.run(self.sample_images_test, feed_dict={self.Z: Z, self.batch_sz: n})\n",
    "        return samples\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def celeb():\n",
    "    X = get_celeb()\n",
    "    # just loads a list of filenames, we will load them in dynamically\n",
    "    # because there are many\n",
    "    dim = 64\n",
    "    colors = 3\n",
    "\n",
    "    # for celeb\n",
    "    d_sizes = {\n",
    "    'conv_layers': [\n",
    "      (64, 5, 2, False),\n",
    "      (128, 5, 2, True),\n",
    "      (256, 5, 2, True),\n",
    "      (512, 5, 2, True)\n",
    "    ],\n",
    "    'dense_layers': [],\n",
    "    }\n",
    "    g_sizes = {\n",
    "    'z': 100,\n",
    "    'projection': 512,\n",
    "    'bn_after_project': True,\n",
    "    'conv_layers': [\n",
    "      (256, 5, 2, True),\n",
    "      (128, 5, 2, True),\n",
    "      (64, 5, 2, True),\n",
    "      (colors, 5, 2, False)\n",
    "    ],\n",
    "    'dense_layers': [],\n",
    "    'output_activation': tf.tanh,\n",
    "    }\n",
    "\n",
    "    # setup gan\n",
    "    # note: assume square images, so only need 1 dim\n",
    "    gan = DCGAN(dim, colors, d_sizes, g_sizes)\n",
    "    gan.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_celeb(limit=None):\n",
    "    if not os.path.exists('../large_files'):\n",
    "        os.mkdir('../large_files')\n",
    "\n",
    "    # eventual place where our final data will reside\n",
    "    if not os.path.exists('../large_files/img_align_celeba-cropped'):\n",
    "\n",
    "        # check for original data\n",
    "        if not os.path.exists('../large_files/img_align_celeba'):\n",
    "            # download the file and place it here\n",
    "            if not os.path.exists('../large_files/img_align_celeba.zip'):\n",
    "                print(\"Downloading img_align_celeba.zip...\")\n",
    "                download_file(\n",
    "                '0B7EVK8r0v71pZjFTYXZWM3FlRnM',\n",
    "                '../large_files/img_align_celeba.zip'\n",
    "                )\n",
    "\n",
    "            # unzip the file\n",
    "            print(\"Extracting img_align_celeba.zip...\")\n",
    "            with zipfile.ZipFile('../large_files/img_align_celeba.zip') as zf:\n",
    "                zip_dir = zf.namelist()[0]\n",
    "                zf.extractall('../large_files')\n",
    "\n",
    "\n",
    "        # load in the original images\n",
    "        filenames = glob(\"../large_files/img_align_celeba/*.jpg\")\n",
    "        N = len(filenames)\n",
    "        print(\"Found %d files!\" % N)\n",
    "\n",
    "\n",
    "        # crop the images to 64x64\n",
    "        os.mkdir('../large_files/img_align_celeba-cropped')\n",
    "        print(\"Cropping images, please wait...\")\n",
    "\n",
    "        for i in range(N):\n",
    "            crop_and_resave(filenames[i], '../large_files/img_align_celeba-cropped')\n",
    "            if i % 1000 == 0:\n",
    "                print(\"%d/%d\" % (i, N))\n",
    "\n",
    "\n",
    "    # make sure to return the cropped version\n",
    "    filenames = glob(\"../large_files/img_align_celeba-cropped/*.jpg\")\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def crop_and_resave(inputfile, outputdir):\n",
    "    # theoretically, we could try to find the face\n",
    "    # but let's be lazy\n",
    "    # we assume that the middle 108 pixels will contain the face\n",
    "    im = imread(inputfile)\n",
    "    height, width, color = im.shape\n",
    "    edge_h = int( round( (height - 108) / 2.0 ) )\n",
    "    edge_w = int( round( (width - 108) / 2.0 ) )\n",
    "\n",
    "    cropped = im[edge_h:(edge_h + 108), edge_w:(edge_w + 108)]\n",
    "    small = imresize(cropped, (64, 64))\n",
    "\n",
    "    filename = inputfile.split('/')[-1]\n",
    "    imsave(\"%s/%s\" % (outputdir, filename), small)\n",
    "\n",
    "\n",
    "def scale_image(im):\n",
    "  # scale to (-1, +1)\n",
    "  return (im / 255.0)*2 - 1\n",
    "\n",
    "def download_file(file_id, dest):\n",
    "    drive_url = \"https://docs.google.com/uc?export=download\"\n",
    "    session = requests.Session()\n",
    "    response = session.get(drive_url, params={'id': file_id}, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = {'id': file_id, 'confirm': token}\n",
    "        response = session.get(drive_url, params=params, stream=True)\n",
    "\n",
    "    save_response_content(response, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading img_align_celeba.zip...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-537000cdccaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mceleb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-52fa3c817ef3>\u001b[0m in \u001b[0;36mceleb\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mceleb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_celeb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# just loads a list of filenames, we will load them in dynamically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# because there are many\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-2cda0455f97b>\u001b[0m in \u001b[0;36mget_celeb\u001b[1;34m(limit)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 download_file(\n\u001b[0;32m     14\u001b[0m                 \u001b[1;34m'0B7EVK8r0v71pZjFTYXZWM3FlRnM'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;34m'../large_files/img_align_celeba.zip'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 )\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-2cda0455f97b>\u001b[0m in \u001b[0;36mdownload_file\u001b[1;34m(file_id, dest)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdownload_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mdrive_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://docs.google.com/uc?export=download\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrive_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_confirm_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "celeb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
